{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prereq.\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    " \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping # used for callback \n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: normalize\n",
    "\n",
    "def normalize_df(df):\n",
    "    x = df.values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the datasets\n",
    "train = pd.read_csv(\"train.csv\") \n",
    "cross = pd.read_csv(\"cross.csv\") \n",
    "test = pd.read_csv(\"test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split in X & Y\n",
    "\n",
    "# training set\n",
    "y = train.iloc[:, -2:]\n",
    "x = normalize_df(train.iloc[:, 0:-2])\n",
    "x = x.drop(x.columns[0], axis=1)\n",
    "\n",
    "\n",
    "# dev set\n",
    "\n",
    "y_c = cross.iloc[:, -2:]\n",
    "x_c = normalize_df(cross.iloc[:, 0:-2])\n",
    "x_c = x_c.drop(x_c.columns[0], axis=1)\n",
    "\n",
    "\n",
    "# test set\n",
    "\n",
    "y_t = test.iloc[:, -2:]\n",
    "x_t = normalize_df(test.iloc[:, 0:-2])\n",
    "x_t = x_t.drop(x_t.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "\n",
    "x = np.asarray(x.to_numpy())\n",
    "y = np.asarray(y.to_numpy())\n",
    "x_t = np.asarray(x_t.to_numpy())\n",
    "y_t = np.asarray(y_t.to_numpy())\n",
    "x_c = np.asarray(x_c.to_numpy())\n",
    "y_c = np.asarray(y_c.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/patriq/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# arhitect the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "layers.Dropout(0.15),\n",
    "layers.Dense(128, activation='relu'),\n",
    "layers.Dropout(0.25),\n",
    "layers.Dense(128, activation='relu'),\n",
    "layers.Dropout(0.25),\n",
    "layers.Dense(128, activation='relu'),\n",
    "layers.Dropout(0.25),\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dropout(0.25),\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dropout(0.15),\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dropout(0.15),\n",
    "layers.Dense(64, activation='relu'),\n",
    "layers.Dropout(0.15),\n",
    "layers.Dense(32, activation='relu'),\n",
    "layers.Dropout(0.1),\n",
    "layers.Dense(32, activation='relu'),\n",
    "layers.Dropout(0.1),\n",
    "layers.Dense(32, activation='relu'),\n",
    "layers.Dropout(0.1),\n",
    "layers.Dense(32, activation='relu'),\n",
    "layers.Dropout(0.1),\n",
    "layers.Dense(16, activation='relu'),\n",
    "layers.Dropout(0.05),\n",
    "layers.Dense(16, activation='relu'),\n",
    "layers.Dropout(0.05),\n",
    "layers.Dense(2, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#the training process stops because of the val_acc â€“ min_delta < baseline for the patience interval (10 epochs). \n",
    "callbacks = [EarlyStopping(monitor='val_acc',verbose=1,min_delta=0.00000001, patience=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "99000/99000 [==============================] - 16s 164us/sample - loss: 0.2259 - acc: 0.8997 - val_loss: 5.1615e-05 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "99000/99000 [==============================] - 14s 142us/sample - loss: 0.0040 - acc: 0.9990 - val_loss: 7.7194e-06 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "99000/99000 [==============================] - 14s 143us/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 2.0859e-06 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "99000/99000 [==============================] - 14s 145us/sample - loss: 0.0025 - acc: 0.9994 - val_loss: 2.1635e-05 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "99000/99000 [==============================] - 14s 145us/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 3.8358e-06 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "99000/99000 [==============================] - 15s 147us/sample - loss: 0.0014 - acc: 0.9996 - val_loss: 7.6190e-07 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "99000/99000 [==============================] - 15s 151us/sample - loss: 0.0011 - acc: 0.9997 - val_loss: 5.2350e-06 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "99000/99000 [==============================] - 15s 155us/sample - loss: 8.8376e-04 - acc: 0.9997 - val_loss: 2.5868e-07 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "99000/99000 [==============================] - 15s 155us/sample - loss: 7.5847e-04 - acc: 0.9998 - val_loss: 2.3662e-06 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "99000/99000 [==============================] - 16s 158us/sample - loss: 7.1052e-04 - acc: 0.9998 - val_loss: 7.6294e-09 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "99000/99000 [==============================] - 16s 164us/sample - loss: 7.1840e-04 - acc: 0.9999 - val_loss: 3.8147e-09 - val_acc: 1.0000\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f102a23efd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x.astype('float32'),y, \n",
    "          epochs=50, \n",
    "          batch_size=99, \n",
    "          shuffle=True, \n",
    "          validation_data=(x_c.astype('float32'), y_c),\n",
    "          callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 236us/sample - loss: 2.2173e-08 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2172822198740504e-08, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_t, y_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this config i achived acc on trian set(99k values) of 99.99%\n",
    "# and acc 100% on test and dev seds\n",
    "model.save('9997predict.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auth: Martinescu Sorin-Alexandru "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
